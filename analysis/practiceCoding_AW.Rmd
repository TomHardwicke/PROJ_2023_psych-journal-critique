---
title: "Results from Primary Coding"
author: "Annie Whamond"
date: "2023-08-28"
output: html_document
---

#Prelim results and visualisations for d_journals using FINAL coding data only
 
```{r}
#Genarate table to assess anyPPC

d_FINAL <- d_journals %>%
  filter(coder_id == "FINAL (TEH)") %>% #keeps only FINAL coded by TEH
  filter(journal_empirical == "Yes") %>%          #removes ineligible journals (not empirical)
  group_by(journal) %>%
#  distinct(journal, .keep_all = TRUE) %>%        #keeps only distinct journal entries
    mutate(anyPPC = case_when(
    anyPPC == 'Unclear' | anyPPC == 'UNSURE' | anyPPC == 'Unclear type' ~ 'UNCLEAR',
    anyPPC == 'NO (explicit statement that PPC is not accepted)' | anyPPC == 'NO (there are no PPC options)' ~ 'NO',
    TRUE ~ anyPPC
    ))

 table(d_FINAL$sampleID, d_FINAL$anyPPC)
 
 table(d_FINAL$sampleID)
```


# Calculate CIs for YES 
```{r}
library(binom)

# Prominent Sample data
prominentSuccess <- 47
randomSuccess <- 29
totalSuccess <- 72

sample_size <- 100
totalSample <- 189
confidence_level <- 0.95

# Calculate the Wilson confidence interval
ci_prominent <- binom.confint(prominentSuccess, sample_size, method = "wilson", conf.level = confidence_level)
ci_random <- binom.confint(randomSuccess, sample_size, method = "wilson", conf.level = confidence_level)
ci_total <- binom.confint(totalSuccess, totalSample, method = "wilson", conf.level = confidence_level)

# Print the confidence interval
print(ci_prominent)
print(ci_random)
print(ci_total)
```



#Look at limitations for anyPPC = YES
```{r}

# Removes journals that do not offer any PPC 
 d_PPConly <- d_FINAL %>%
   filter(anyPPC == "YES")

#Look at stated length limits
PPC_length <- d_PPConly %>%
  filter(ppc_length_A != "NO") %>%
  filter(ppc_length_A != "NOT STATED")


table(PPC_length$ppc_length_A)
table(PPC_length$ppc_length_B)

#Look at stated time limits

PPC_time <- d_PPConly %>%
  filter(ppc_time_A != "NOT STATED")

table(PPC_time$ppc_time_A)
  
```

#Add COPE status
```{r}
# Load googlesheet data

dj_prominent <- read_csv(here('data','raw', 'journals-prominent.csv')) %>% #loads csv of googlesheet data of prominent journals
  slice_head(n = 114) %>%
  select('journal' = 'journal_name', 'COPE' = 'COPE (T = member; F = not a member)' )

dj_random <- read_csv(here('data','raw', 'journals-random.csv')) %>% #loads csv of googlesheet data of random journals
  slice_head(n = 108) %>%
  select('journal' = 'journal_name', 'COPE' = 'COPE (T = member; F = not a member)' )

# Combine above CSVs to one tibble

dj_cope <- bind_rows(dj_prominent, dj_random)

# Identify duplicate rows
duplicates <- duplicated(dj_cope)

# Select the duplicate rows
duplicate_rows <- dj_cope[duplicates, ]

# Check if duplicate rows have the same COPE values for journals
for (i in seq_len(nrow(duplicate_rows))) {
  row <- duplicate_rows[i, ]
  id <- row$ID
  value <- row$Value
  same_values <- all(duplicate_rows$Value[duplicate_rows$ID == id] == value)
  
  if (same_values) {
    cat("Row", i, "with ID =", id, "has the same values in both columns.\n")
  } else {
    cat("Row", i, "with ID =", id, "has different values in both columns.\n")
  }
}

#All 14 duplicated (both sample) journals had consistent COPE status, remove duplicates
dj_cope <- distinct(dj_cope, journal, .keep_all = T)


#join with main data tibble:
d_FINAL <- left_join(d_FINAL, dj_cope, by = 'journal')

```

#join() Code from checkData.RMD for importing JIFs and category


d_journals_prominent <- left_join(d_journals_prominent, journal_list_prominent_all, by = 'journal')

journal_list_random_all <- journal_list_random_all %>%
  select(journal = Journal, WOS_first_psych_category)

d_journals_random <- left_join(d_journals_random, journal_list_random_all, by = 'journal')

journal_list_prominent_all <- journal_list_prominent_all %>%
  select(-WOS_first_psych_category)
  
d_journals_random <- left_join(d_journals_random, journal_list_prominent_all, by = 'journal')

tmp <- d_journals_random %>% filter(is.na(`2021 JIF`)) %>% distinct(journal, .keep_all = T)
write_csv(tmp,here('data', 'prepareSample', 'journals', '02 - modified', 'we_need_jifs.csv'))


# Bar graph of PPC by COPE

```{r}

# Create bar plot
d_FINAL %>%  
  ggplot() +
geom_bar(
  mapping = aes(x=anyPPC, fill = COPE),
  stat = "count",
  position = "stack",
  colour = "black",
  just = 0.5,
  width = 0.7,
  na.rm = FALSE,
  orientation = NA,
  show.legend = TRUE,
  inherit.aes = TRUE
) +
  theme_bw() +
  scale_fill_brewer(palette = "Blues")
 # facet_wrap(~field) +
  labs(title = "Journal PPC Acceptance by COPE membership", x = "Accepts PPC", y = "Count")
```
