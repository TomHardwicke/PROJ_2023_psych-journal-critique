---
title: "Results Coding"
author: "Annie Whamond"
date: "2023-08-28"
output: html_document
---

# Load libraries

```{r}
library(tidyverse)
library(ggplot2)
library(RColorBrewer)
library(dplyr)
library(kableExtra) # for tables
library(knitr) # for literate programming
library(janitor) # for data munging
library(tidylog) # for inline code feedback
library(here) # for finding files
library(validate) # for data validation and testing
#library(ggthemr) # for ggplot theme
library(ggrepel) # for ggplot text labels
library(scales) # to wrap text on axis labels
library(ggdist) # for plotting distributions
library(patchwork) # for multipanel plot layouts
library(ggbeeswarm) # for dotplots
```



# Load processed data files
```{r}

d_journals <- read_csv(here('data','processed','d_journals.csv'))
d_articles <- read_csv(here('data','processed','d_articles.csv'))

```
# Create separate tibbles for Prominent and Randomly-selected journal samples
```{r}
dj_prominent <- d_journals %>%
  filter(sample_id != "random") %>%
  filter(is_empirical == TRUE)

dj_random <- d_journals %>%
  filter(sample_id != "prominent") %>%
  filter(is_empirical == TRUE)
```
# DESCRIPTIVE STATISTICS

# JIF median and IQR (prominent sample)
```{r}

# Calculate mean and median JIF for entire prominent sample
dj_prominent %>%
  filter(ppc_type == "A") %>%
  mutate(jif = round(jif, 2)) %>%
  summarise(mean(jif), median(jif))
```

# JIF median and IQR by subfield (prominent sample)
```{r}
# Group the tibble by the 'field' column
prom_grouped <- dj_prominent %>% 
  filter(ppc_type == "A") %>%
  group_by(field)

# Compute summary statistics for 'jif' within each group
promJIF_stats <- prom_grouped %>%
  mutate(jif = round(jif, 2)) %>%
  summarize(
    mean_jif = mean(jif),
    median_jif = median(jif),
    q1_jif = quantile(jif, 0.25),
    q3_jif = quantile(jif, 0.75),
    iqr_jif = quantile(jif, 0.75) - quantile(jif, 0.25),
    count = n()
  )

# View the summary statistics
print(promJIF_stats)
```

# JIF median and IQR (random sample)
``` {r}
# Calculate mean and median JIF for entire random sample
dj_random %>%
  filter(ppc_type == "A") %>%
  filter(!is.na(jif)) %>%
  mutate(jif = round(jif, 2)) %>%
  summarise(mean(jif), median(jif))
```

# JIF median and IQR by subfield (random sample)
```{r}
# Group the tibble by the 'field' column
rand_grouped <- dj_random %>% 
  filter(ppc_type == "A") %>%
  filter(!is.na(jif)) %>% 
  group_by(field)

# Compute summary statistics for 'jif' within each group
randJIF_stats <- rand_grouped %>%
  filter(ppc_type == "A") %>%
  filter(is_empirical == "TRUE") %>%
  mutate(jif = round(jif, 2)) %>%
  summarize(
    mean_jif = mean(jif),
    median_jif = median(jif),
    q1_jif = quantile(jif, 0.25),
    q3_jif = quantile(jif, 0.75),
    iqr_jif = quantile(jif, 0.75) - quantile(jif, 0.25),
    count = n()
  )

# View the summary statistics
print(randJIF_stats)

dj_random %>%
   filter(!is.na(jif)) %>%
  mutate(jif = round(jif, 2)) %>%
  summarize(
    mean_jif = mean(jif),
    median_jif = median(jif),
    q1_jif = quantile(jif, 0.25),
    q3_jif = quantile(jif, 0.75),
    iqr_jif = quantile(jif, 0.75) - quantile(jif, 0.25),
    count = n()
  )
  

```

# Journal PPC Policy Overview
```{r}

d_journals_anyPPC <- d_journals %>%
  filter(ppc_type == "A") %>% # Filters to a single row for each journal
  filter(is_empirical == "TRUE") # Remove excluded journals

table(d_journals_anyPPC$sample_id)
table(d_journals_anyPPC$has_ppc)
table(d_journals_anyPPC$has_ppc, d_journals_anyPPC$sample_id)

```

# PPC policy by COPE membership status (prominent sample)
```{r}

table_PPCbyCOPEprom <- dj_prominent %>%
  filter(ppc_type == "A" & is_empirical == TRUE) %>%
  count(has_ppc, cope)

print(table_PPCbyCOPEprom)

```

# PPC policy by COPE membership status (random sample)
```{r}

table_PPCbyCOPErand <- dj_random %>%
  filter(ppc_type == "A" & is_empirical == TRUE) %>%
  count(has_ppc, cope)

print(table_PPCbyCOPErand)

```




# Descriptives for each journal sample [**EDIT so these tables show ppc_type == "A" only**]
```{r}
table(dj_prominent$field, dj_prominent$has_ppc)
table(dj_random$field, dj_random$has_ppc)

table(dj_prominent$field, dj_prominent$cope)
table(dj_random$field, dj_random$cope)
```

# ANALYSIS

# Calculate CIs for YES [**EDIT TO DERIVE NUMBERS FROM DATA**]
Not sure if this makes sense to do for Prominent and Total, as these are not random samples
```{r}
library(binom)

# Prominent Sample data
prominentSuccess <- 1
randomSuccess <- 23
totalSuccess <- 57

sample_size <- 100
totalSample <- 189
confidence_level <- 0.95

# Calculate the Wilson confidence interval
ci_prominent <- binom.confint(prominentSuccess, sample_size, method = "wilson", conf.level = confidence_level)
ci_random <- binom.confint(randomSuccess, sample_size, method = "wilson", conf.level = confidence_level)
ci_total <- binom.confint(totalSuccess, totalSample, method = "wilson", conf.level = confidence_level)

# Print the confidence interval
print(ci_prominent)
print(ci_random)
print(ci_total)
```

# Calculate CIs for NO [**EDIT TO DERIVE NUMBERS FROM DATA**]
```{r}
library(binom)

# Prominent Sample data
prominentNO <- 77
randomNO <- 74
totalNO <- 123


# Calculate the Wilson confidence interval
ci_prominentNO <- binom.confint(prominentNO, sample_size, method = "wilson", conf.level = confidence_level)
ci_randomNO <- binom.confint(randomNO, sample_size, method = "wilson", conf.level = confidence_level)
ci_totalNO <- binom.confint(totalNO, totalSample, method = "wilson", conf.level = confidence_level)

# Print the confidence interval
print(ci_prominentNO)
print(ci_randomNO)
print(ci_totalNO)
```

# Look at PPC names
```{r}

table(d_journals$ppc_name)  #PPC names from all entries
table(d_journals$sample_id, d_journals$ppc_name) #PPC names from each sample

```
Total = 63, 5 journals offering 2 types


# PPC length limitations (Prominent)
```{r}

table(dj_prominent$ppc_length, dj_prominent$ppc_name)

```
# PPC length limitations (Random)
```{r}

table(dj_random$ppc_length, dj_random$ppc_name)

```
# PPC time limitations (Prominent)
``` {r}

table(dj_prominent$ppc_time, dj_prominent$ppc_name)

  
```

# PPC time limitations (Random)
```{r}

table(dj_random$ppc_time, dj_random$ppc_name)

```


# Create and combine restiction statement graphs with ppc acceptance (prominent sample)
```{r}

# Filter and transform restrictions for ppc_length
ppc_length_data <- dj_prominent %>%
  filter(!is.na(ppc_name)) %>%
  filter(has_ppc != "ARCHIVE") %>% # removes Archive Only PPC types
  mutate(ppc_length = case_when(
    ppc_length %in% c(1000, 1100, 1200, 1500, 2000, 2500, 2650, 3000, 3500, 400, 500, 5000, 750, 800, 8000) ~ 'Quantitative',
    ppc_length == "NOT STATED" ~ "Not Stated",
    TRUE ~ 'Qualitative' # Summarises all length limits as 'Quantitative', 'Qualitative', or 'Not Stated'
  )) %>% 
  group_by(ppc_length) %>%
  summarise(count = n())

# Filter and transform restrictions for ppc_time
ppc_time_data <- dj_prominent %>%
  filter(!is.na(ppc_name)) %>%
  filter(has_ppc != "ARCHIVE") %>%
  mutate(ppc_time = case_when(
    ppc_time %in% c(13.05, 26.1, 39.15, 4, 52) ~ 'Quantitative',
    ppc_time == "NOT STATED" ~ "Not Stated",
    TRUE ~ 'Qualitative' # Summarises all time limits as 'Quantitative', 'Qualitative', or 'Not Stated'
  )) %>%
  group_by(ppc_time) %>%
  summarise(count = n())

# Combine the data and unite the columns
combined_data <- bind_rows(
  ppc_length_data %>% mutate(Code = "Length"),
  ppc_time_data %>% mutate(Code = "Time-to-submit")
) %>%
unite(limits, ppc_length, ppc_time) %>%
  mutate(limits = case_when(limits == "Not Stated_NA" ~ "Not Stated",
                   limits == "Qualitative_NA" ~ "Qualitative",
                   limits == "Quantitative_NA" ~ "Quantitative",
                   limits == "NA_Not Stated" ~ "Not Stated",
                   limits == "NA_Qualitative" ~ "Qualitative",
                   limits == "NA_Quantitative" ~ "Quantitative",
                   TRUE ~ as.character(limits)
                   ))


# Create the first graph
graph1 <- ggplot(combined_data, aes(x = Code, y = count, fill = limits)) +
  geom_bar(stat = "identity", 
           position = "stack",
           colour = "black") +
  theme_bw() +
  scale_fill_brewer(palette = "Blues") +
  labs(x = "Restriction Type", y = "Count", fill = "Restrictions")

# Create the second graph
graph2 <- dj_prominent %>%
  filter(ppc_type == "A") %>% # Keeps only first PPC row for each journal
  filter(!is.na(has_ppc)) %>%
  mutate(has_ppc = case_when(
    has_ppc == 'ARCHIVE' ~ 'Archive',
    has_ppc == 'NO EXPLICIT' ~ 'No Explicit',
    has_ppc == 'NO IMPLICIT' ~ 'No Implicit',
    has_ppc == 'YES' ~ 'Yes',
    TRUE ~ has_ppc
  )) %>%
  group_by(has_ppc) %>%
  summarise(count = n()) %>%
  mutate(percentage = count / sum(count) * 100) %>%
  ggplot(aes(x = "", y = count, fill = has_ppc)) +
  geom_bar(stat = "identity",
           colour = "black") +
  theme_bw() +
  scale_fill_brewer(palette = "Oranges") +
  labs(x = "Journal Policy", y = "Count", fill = "Accepts PPC")

# Arrange both graphs in the same figure
combined_plots <- graph2 + graph1
combined_plots


ggsave(filename = "Prominent_statements.png", plot = last_plot(), device = "png")
```
# Create and combine restiction statement graphs with ppc acceptance (random sample)
```{r}

# Filter and process data for ppc_length
ppc_length_random <- d_journals %>%
  filter(sample_id %in% c("random", "both")) %>%
  filter(!is.na(ppc_name)) %>%
  filter(has_ppc != "ARCHIVE") %>%
  mutate(ppc_length = case_when(
    ppc_length %in% c(1000, 1100, 1200, 1500, 2000, 2500, 2650, 3000, 3500, 400, 500, 5000, 750, 800, 8000) ~ 'Quantitative',
    ppc_length == "NOT STATED" ~ "Not Stated",
    TRUE ~ 'Qualitative'
  )) %>%
  group_by(ppc_length) %>%
  summarise(count = n())

# Filter and process data for ppc_time
ppc_time_random<- d_journals %>%
  filter(sample_id %in% c("random", "both")) %>%
  filter(!is.na(ppc_name)) %>%
  filter(has_ppc != "ARCHIVE") %>%
  mutate(ppc_time = case_when(
    ppc_time %in% c(13.05, 26.1, 39.15, 4, 52) ~ 'Quantitative',
    ppc_time == "NOT STATED" ~ "Not Stated",
    TRUE ~ 'Qualitative'
  )) %>%
  group_by(ppc_time) %>%
  summarise(count = n())

# Combine the data and unite the columns
combined_data_random <- bind_rows(
  ppc_length_random %>% mutate(Code = "Length"),
  ppc_time_random %>% mutate(Code = "Time-to-submit")
) %>%
unite(limits, ppc_length, ppc_time) %>%
  mutate(limits = case_when(limits == "Not Stated_NA" ~ "Not Stated",
                   limits == "Qualitative_NA" ~ "Qualitative",
                   limits == "Quantitative_NA" ~ "Quantitative",
                   limits == "NA_Not Stated" ~ "Not Stated",
                   limits == "NA_Qualitative" ~ "Qualitative",
                   limits == "NA_Quantitative" ~ "Quantitative",
                   TRUE ~ as.character(limits)
                   ))


# Create the first graph
graph4 <- ggplot(combined_data_random, aes(x = Code, y = count, fill = limits)) +
  geom_bar(stat = "identity", 
           position = "stack",
           colour = "black") +
  theme_bw() +
  scale_fill_brewer(palette = "Blues") +
  labs(x = "Restriction Type", y = "Count", fill = "Restrictions")

# Create the second graph
graph3 <- d_journals %>%
  filter(sample_id == "random" | sample_id == "both") %>%
  filter(ppc_type == "A") %>%
  filter(!is.na(has_ppc)) %>%
  mutate(has_ppc = case_when(
    has_ppc == 'ARCHIVE' ~ 'Archive',
    has_ppc == 'NO EXPLICIT' ~ 'No Explicit',
    has_ppc == 'NO IMPLICIT' ~ 'No Implicit',
    has_ppc == 'YES' ~ 'Yes',
    TRUE ~ has_ppc
  )) %>%
  group_by(has_ppc) %>%
  summarise(count = n()) %>%
  mutate(percentage = count / sum(count) * 100) %>%
  ggplot(aes(x = "", y = count, fill = has_ppc)) +
  geom_bar(stat = "identity",
           colour = "black") +
  theme_bw() +
  scale_fill_brewer(palette = "Oranges") +
  labs(x = "Journal Policy", y = "Count", fill = "Accepts PPC")

# Arrange both graphs in the same figure
combined_plots <- graph3 + graph4
combined_plots

ggsave(filename = "Random_statements.png", plot = last_plot(), device = "png")

```

# PPC Reference limits
```{r}
table(dj_prominent$ppc_ref, dj_prominent$ppc_name)
table(dj_random$ppc_ref, dj_random$ppc_name)

```
# PPC Peer Review
```{r}
table(dj_prominent$ppc_review, dj_prominent$ppc_name)
table(dj_random$ppc_review, dj_random$ppc_name)

```


# Bar graph of PPC by COPE

```{r}
library(ggplot2)
library(RColorBrewer)

# Overall
d_journals %>%  
  mutate(has_ppc = case_when(
    has_ppc == 'ARCHIVE' ~ 'YES',
    has_ppc == 'NO EXPLICIT' | has_ppc == 'NO IMPLICIT' ~ 'NO',
    TRUE ~ has_ppc
    )) %>%
  filter(ppc_type == "A") %>%
  filter(has_ppc == "YES" | has_ppc == "NO") %>%
  ggplot() +
geom_bar(
  mapping = aes(x=has_ppc, fill = cope),
  stat = "count",
  position = "stack",
  colour = "black",
  just = 0.5,
  width = 0.7,
  na.rm = FALSE,
  orientation = NA,
  show.legend = TRUE,
  inherit.aes = TRUE
) +
  theme_bw() +
  scale_fill_brewer(palette = "Blues") +
  labs(title = "Journal PPC Acceptance by COPE membership", x = "Accepts PPC", y = "Count")

```

``` {r}
# Prominent Sample
d_journals %>%  
  filter(sample_id == "prominent" | sample_id == "both") %>%
  mutate(has_ppc = case_when(
    has_ppc == 'ARCHIVE' ~ 'NO',
    has_ppc == 'NO EXPLICIT' | has_ppc == 'NO IMPLICIT' ~ 'NO',
    TRUE ~ has_ppc
    )) %>%
  filter(ppc_type == "A") %>%
  filter(has_ppc == "YES" | has_ppc == "NO") %>%
  ggplot() +
geom_bar(
  mapping = aes(x=has_ppc, fill = cope),
  stat = "count",
  position = "stack",
  colour = "black",
  just = 0.5,
  width = 0.7,
  na.rm = FALSE,
  orientation = NA,
  show.legend = TRUE,
  inherit.aes = TRUE
) +
  theme_bw() +
  scale_fill_brewer(palette = "Oranges") +
  labs(title = "Prominent Journal PPC Acceptance by COPE membership", x = "Accepts PPC", y = "Count", fill = "COPE")

ggsave(filename= "ProminentPPC_policyByCope.png", device= "png")
```


``` {r}
# Random Sample
d_journals %>%  
  filter(sample_id == "random" | sample_id == "both") %>%
  mutate(has_ppc = case_when(
    has_ppc == 'ARCHIVE' ~ 'YES',
    has_ppc == 'NO EXPLICIT' | has_ppc == 'NO IMPLICIT' ~ 'NO',
    TRUE ~ has_ppc
    )) %>%
  filter(ppc_type == "A") %>%
  filter(has_ppc == "YES" | has_ppc == "NO") %>%
  ggplot() +
geom_bar(
  mapping = aes(x=cope, fill = has_ppc),
  stat = "count",
  position = "stack",
  colour = "black",
  just = 0.5,
  width = 0.7,
  na.rm = FALSE,
  orientation = NA,
  show.legend = TRUE,
  inherit.aes = TRUE
) +
  theme_bw() +
  scale_fill_brewer(palette = "Oranges") +
  labs(title = "Random Journal PPC Acceptance by COPE membership", x = "COPE Member", y = "Count", fill = "PPC")

ggsave(filename= "RandomPPC_policyByCope.png", device= "png")
```

# Restriction Statements Graph
```{r}

table(dj_prominent$ppc_ref)
table(dj_prominent$ppc_review)
  
table(dj_random$ppc_ref)
table(dj_random$ppc_review)
```




```{r}
count_non_missing <- sum(!is.na(dj_prominent$ppc_length))
cat("Count of non-missing values in ppc_length:", count_non_missing, "\n")
```


# View median and IQR for quantitavtive 'Commentary' limits in prominent journals
```{r}

promCom_stats <- dj_prominent %>%
  filter(ppc_name == "Commentary") %>%
  mutate(
    ppc_length = as.numeric(replace(ppc_length, ppc_length %in% c("Qualitative", "NOT STATED"), NA)),
    ppc_time = as.numeric(replace(ppc_time, ppc_time %in% c("Qualitative", "NOT STATED"), NA)),
    ppc_ref = as.numeric(replace(ppc_ref, ppc_ref %in% c("Qualitative", "NOT STATED"), NA))
  ) %>%
  summarize(
    mdLength = median(ppc_length, na.rm = TRUE),
    mdTime = median(ppc_time, na.rm = TRUE),
    mdRef = median(ppc_ref, na.rm = TRUE),
    q1_length = quantile(ppc_length, 0.25, na.rm = TRUE),
    q3_length = quantile(ppc_length, 0.75, na.rm = TRUE),
    iqr_length = quantile(ppc_length, 0.75, na.rm = TRUE) - quantile(ppc_length, 0.25, na.rm = TRUE),
    q1_time = quantile(ppc_time, 0.25, na.rm = TRUE),
    q3_time = quantile(ppc_time, 0.75, na.rm = TRUE),
    iqr_time = quantile(ppc_time, 0.75, na.rm = TRUE) - quantile(ppc_time, 0.25, na.rm = TRUE),
    q1_ref = quantile(ppc_ref, 0.25, na.rm = TRUE),
    q3_ref = quantile(ppc_ref, 0.75, na.rm = TRUE),
    iqr_ref = quantile(ppc_ref, 0.75, na.rm = TRUE) - quantile(ppc_ref, 0.25, na.rm = TRUE),
    peer_rev = sum(ppc_review == "YES"),
    COPE = sum(cope == "TRUE")
  )

print(promCom_stats)

```
# View median and IQR for quantitavtive 'Letters' limits in prominent journals
```{r}
promLet_stats <- dj_prominent %>%
  filter(ppc_name == "Letters") %>%
  mutate(
    ppc_length = as.numeric(ppc_length),  # Convert ppc_length to numeric
    ppc_time = as.numeric(ppc_time),      # Convert ppc_time to numeric
    ppc_ref = as.numeric(ppc_ref)         # Convert ppc_ref to numeric
  ) %>%
  summarize(
    mdLength = median(ppc_length, na.rm = TRUE),
    mdTime = median(ppc_time, na.rm = TRUE),
    mdRef = median(ppc_ref, na.rm = TRUE),
    q1_length = quantile(ppc_length, 0.25, na.rm = TRUE),
    q3_length = quantile(ppc_length, 0.75, na.rm = TRUE),
    iqr_length = quantile(ppc_length, 0.75, na.rm = TRUE) - quantile(ppc_length, 0.25, na.rm = TRUE),
    q1_time = quantile(ppc_time, 0.25, na.rm = TRUE),
    q3_time = quantile(ppc_time, 0.75, na.rm = TRUE),
    iqr_time = quantile(ppc_time, 0.75, na.rm = TRUE) - quantile(ppc_time, 0.25, na.rm = TRUE),
    q1_ref = quantile(ppc_ref, 0.25, na.rm = TRUE),
    q3_ref = quantile(ppc_ref, 0.75, na.rm = TRUE),
    iqr_ref = quantile(ppc_ref, 0.75, na.rm = TRUE) - quantile(ppc_ref, 0.25, na.rm = TRUE),
    peer_rev = sum(ppc_review == "YES"),
    COPE = sum(cope == "TRUE")
  )
  
print(promLet_stats)
```
# View median and IQR for ALL quantitavtive limits in PROMINENT journals
```{r}

promAll_stats <- dj_prominent %>%
  filter(ppc_name == "Commentary" | ppc_name == "Letters") %>%
  mutate(
    ppc_length = as.numeric(replace(ppc_length, ppc_length %in% c("Qualitative", "NOT STATED"), NA)),
    ppc_time = as.numeric(replace(ppc_time, ppc_time %in% c("Qualitative", "NOT STATED"), NA)),
    ppc_ref = as.numeric(replace(ppc_ref, ppc_ref %in% c("Qualitative", "NOT STATED"), NA))
  ) %>%
  summarize(
    mdLength = median(ppc_length, na.rm = TRUE),
    mdTime = median(ppc_time, na.rm = TRUE),
    mdRef = median(ppc_ref, na.rm = TRUE),
    q1_length = quantile(ppc_length, 0.25, na.rm = TRUE),
    q3_length = quantile(ppc_length, 0.75, na.rm = TRUE),
    iqr_length = quantile(ppc_length, 0.75, na.rm = TRUE) - quantile(ppc_length, 0.25, na.rm = TRUE),
    q1_time = quantile(ppc_time, 0.25, na.rm = TRUE),
    q3_time = quantile(ppc_time, 0.75, na.rm = TRUE),
    iqr_time = quantile(ppc_time, 0.75, na.rm = TRUE) - quantile(ppc_time, 0.25, na.rm = TRUE),
    q1_ref = quantile(ppc_ref, 0.25, na.rm = TRUE),
    q3_ref = quantile(ppc_ref, 0.75, na.rm = TRUE),
    iqr_ref = quantile(ppc_ref, 0.75, na.rm = TRUE) - quantile(ppc_ref, 0.25, na.rm = TRUE),
    peer_rev = sum(ppc_review == "YES"),
    COPE = sum(cope == "TRUE"),
    count = n()
  )

print(promAll_stats)

```

# View median and IQR for quantitavtive 'Commentary' limits in Random journals
```{r}

randCom_stats <- dj_random %>%
  filter(ppc_name == "Commentary") %>%
  mutate(
    ppc_length = as.numeric(replace(ppc_length, ppc_length %in% c("Qualitative", "NOT STATED"), NA)),
    ppc_time = as.numeric(replace(ppc_time, ppc_time %in% c("Qualitative", "NOT STATED"), NA)),
    ppc_ref = as.numeric(replace(ppc_ref, ppc_ref %in% c("Qualitative", "NOT STATED"), NA))
  ) %>%
 summarize(
    mdLength = median(ppc_length, na.rm = TRUE),
    mdTime = median(ppc_time, na.rm = TRUE),
    mdRef = median(ppc_ref, na.rm = TRUE),
    q1_length = quantile(ppc_length, 0.25, na.rm = TRUE),
    q3_length = quantile(ppc_length, 0.75, na.rm = TRUE),
    iqr_length = quantile(ppc_length, 0.75, na.rm = TRUE) - quantile(ppc_length, 0.25, na.rm = TRUE),
    q1_time = quantile(ppc_time, 0.25, na.rm = TRUE),
    q3_time = quantile(ppc_time, 0.75, na.rm = TRUE),
    iqr_time = quantile(ppc_time, 0.75, na.rm = TRUE) - quantile(ppc_time, 0.25, na.rm = TRUE),
    q1_ref = quantile(ppc_ref, 0.25, na.rm = TRUE),
    q3_ref = quantile(ppc_ref, 0.75, na.rm = TRUE),
    iqr_ref = quantile(ppc_ref, 0.75, na.rm = TRUE) - quantile(ppc_ref, 0.25, na.rm = TRUE),
    peer_rev = sum(ppc_review == "YES"),
    COPE = sum(cope == "TRUE")
  )

print(randCom_stats)

```



# View median and IQR for quantitavtive 'Letters' limits in RANDOM journals
```{r}
randLet_stats <- dj_random %>%
  filter(ppc_name == "Letters") %>%
  mutate(
    ppc_length = as.numeric(ppc_length),  # Convert ppc_length to numeric
    ppc_time = as.numeric(ppc_time),      # Convert ppc_time to numeric
    ppc_ref = as.numeric(ppc_ref)         # Convert ppc_ref to numeric
  ) %>%
 summarize(
    mdLength = median(ppc_length, na.rm = TRUE),
    mdTime = median(ppc_time, na.rm = TRUE),
    mdRef = median(ppc_ref, na.rm = TRUE),
    q1_length = quantile(ppc_length, 0.25, na.rm = TRUE),
    q3_length = quantile(ppc_length, 0.75, na.rm = TRUE),
    iqr_length = quantile(ppc_length, 0.75, na.rm = TRUE) - quantile(ppc_length, 0.25, na.rm = TRUE),
    q1_time = quantile(ppc_time, 0.25, na.rm = TRUE),
    q3_time = quantile(ppc_time, 0.75, na.rm = TRUE),
    iqr_time = quantile(ppc_time, 0.75, na.rm = TRUE) - quantile(ppc_time, 0.25, na.rm = TRUE),
    q1_ref = quantile(ppc_ref, 0.25, na.rm = TRUE),
    q3_ref = quantile(ppc_ref, 0.75, na.rm = TRUE),
    iqr_ref = quantile(ppc_ref, 0.75, na.rm = TRUE) - quantile(ppc_ref, 0.25, na.rm = TRUE),
    peer_rev = sum(ppc_review == "YES"),
    COPE = sum(cope == "TRUE")
  )
  
print(randLet_stats)
```

# View median and IQR for ALL quantitavtive limits in RANDOM journals
```{r}

randAll_stats <- dj_random %>%
  filter(ppc_name == "Commentary" | ppc_name == "Letters" | ppc_name == "Other") %>%
  mutate(
    ppc_length = as.numeric(replace(ppc_length, ppc_length %in% c("Qualitative", "NOT STATED"), NA)),
    ppc_time = as.numeric(replace(ppc_time, ppc_time %in% c("Qualitative", "NOT STATED"), NA)),
    ppc_ref = as.numeric(replace(ppc_ref, ppc_ref %in% c("Qualitative", "NOT STATED"), NA))
  ) %>%
  summarize(
    mdLength = median(ppc_length, na.rm = TRUE),
    mdTime = median(ppc_time, na.rm = TRUE),
    mdRef = median(ppc_ref, na.rm = TRUE),
    q1_length = quantile(ppc_length, 0.25, na.rm = TRUE),
    q3_length = quantile(ppc_length, 0.75, na.rm = TRUE),
    iqr_length = quantile(ppc_length, 0.75, na.rm = TRUE) - quantile(ppc_length, 0.25, na.rm = TRUE),
    q1_time = quantile(ppc_time, 0.25, na.rm = TRUE),
    q3_time = quantile(ppc_time, 0.75, na.rm = TRUE),
    iqr_time = quantile(ppc_time, 0.75, na.rm = TRUE) - quantile(ppc_time, 0.25, na.rm = TRUE),
    q1_ref = quantile(ppc_ref, 0.25, na.rm = TRUE),
    q3_ref = quantile(ppc_ref, 0.75, na.rm = TRUE),
    iqr_ref = quantile(ppc_ref, 0.75, na.rm = TRUE) - quantile(ppc_ref, 0.25, na.rm = TRUE),
    peer_rev = sum(ppc_review == "YES"),
    COPE = sum(cope == "TRUE"),
    count = n()
  )

print(randAll_stats)

```



#Coder Disagreements
```{r}

d_journals %>%
  filter(coder_id != "FINAL (TEH)") %>%
  

```

# PREVALENCE ESTIMATES

# Calculate CIs for preavalence [**EDIT TO IMPORT VALUES FROM DATA**]
```{r}
library(binom)

# Prominent Sample data for linked
plPPCsuccess <- 1 #PPC events in prominent sample
rlPPCsuccess <- 0 #PPC events in random sample
linkedSample <- 101 #total sample size

confidence_level <- 0.95

# Calculate the Wilson confidence interval
ci_plPPC <- binom.confint(plPPCsuccess, linkedSample, method = "wilson", conf.level = confidence_level)
ci_rlPPC <- binom.confint(rlPPCsuccess, linkedSample, method = "wilson", conf.level = confidence_level)

# Print the confidence interval
print(ci_plPPC)
print(ci_rlPPC)

```
 
# GRAPH FOR PRESENTATION
# PPC Policy by Sample

```{r}

library(dplyr)
library(ggplot2)
library(forcats)

library(dplyr)

# Duplicate rows with sample_id "both" and rename the duplicates as "Prominent"
duplicated_prominent_rows <- d_journals %>%
    mutate(has_ppc = case_when(
    has_ppc == 'ARCHIVE' | has_ppc == 'NO EXPLICIT' | has_ppc == 'NO IMPLICIT' ~ 'NO',
    TRUE ~ has_ppc
  )) %>%
  filter(ppc_type == "A") %>%
  filter(is_empirical == TRUE) %>%
  filter(sample_id == "both") %>%
  mutate(sample_id = "prominent") 

# Combine the duplicated "Prominent" rows with the original data
d_journals_processed <- bind_rows(d_journals, duplicated_prominent_rows) %>%
  mutate(sample_id = recode(sample_id, "prominent" = "Prominent", "random" = "Random"))

# Now, the dataset contains the original "both" rows and their duplicates as "Prominent"

  
d_journals_processed %>%
   mutate(has_ppc = case_when(
    has_ppc == 'ARCHIVE' | has_ppc == 'NO EXPLICIT' | has_ppc == 'NO IMPLICIT' ~ 'NO',
    TRUE ~ has_ppc
  )) %>%
  filter(ppc_type == "A") %>%
  filter(is_empirical == TRUE) %>%
  mutate(sample_id = ifelse(sample_id == "both", "Random", sample_id)) %>%
  ggplot() +
  geom_bar(
    mapping = aes(x = has_ppc, fill = sample_id),
    stat = "count",
    position = position_dodge(width = 0.8),  # Use position = "dodge" to create side-by-side bars
    colour = "black",
    alpha = 0.7,
    width = 0.7,
    na.rm = FALSE,
    orientation = "vertical",
    show.legend = TRUE,
    inherit.aes = TRUE
  ) +
  geom_text(
    aes(x = has_ppc, y = ..count.., label = ..count.., group = sample_id),
    stat = "count",
    position = position_dodge(width = 0.8),
    vjust = -0.5,  # Adjust the vertical position of the labels
    size = 6
  ) +
  theme_bw() +
  ylim(0, 100) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "Journal PPC Acceptance by Sample",
       x = "Accepts PPC",
       y = "Count",
       fill = "Sample"  # Customize the legend title here
  ) + 
  theme(
    text = element_text(size = 18)  # Increase the font size here
  )

ggsave(filename = "PPCbySample.png", plot = last_plot(), device = "png")
``` 