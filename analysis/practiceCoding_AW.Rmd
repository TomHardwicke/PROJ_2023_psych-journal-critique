---
title: "Results from Primary Coding"
author: "Annie Whamond"
date: "2023-08-28"
output: html_document
---

#Prelim results and visualisations for d_journals using Primary coding data only
 
```{r}
#Genarate table to assess anyPPC

d_primaryONLY <- d_journals %>%
  filter(coder_id == "AW" | coder_id == "NM") %>% #keeps only entries with primary coder initials from main data tibble d_journals
  filter(journal_empirical == "Yes") %>%          #removes ineligible journals (not empirical)
  group_by(journal) %>%
  distinct(journal, .keep_all = TRUE)             #keeps only distinct journal entries

 table(d_primaryONLY$sampleID, d_primaryONLY$anyPPC)
 
 table(d_primaryONLY$sampleID)
```

#Look at limitations for anyPPC = YES
```{r}

# Removes journals that do not offer any PPC 
 d_PPConly <- d_primaryONLY %>%
   filter(anyPPC == "YES")

#Look at stated length limits
PPC_length <- d_PPConly %>%
  filter(ppc_length_A != "NO") %>%
  filter(ppc_length_A != "NOT STATED")


table(PPC_length$ppc_length_A)
table(PPC_length$ppc_length_B)

#Look at stated time limits

PPC_time <- d_PPConly %>%
  filter(ppc_time_A != "NOT STATED")

table(PPC_time$ppc_time_A)
  
```

#Add COPE status
```{r}
# Load googlesheet data

dj_prominent <- read_csv(here('data','raw', 'journalList_PROMINENT.csv')) %>% #loads csv of googlesheet data of prominent journals
  slice_head(n = 114) %>%
  select('journal' = 'journal_name', 'COPE' = 'COPE (T = member; F = not a member)' )

dj_random <- read_csv(here('data','raw', 'journalList_RANDOM.csv')) %>% #loads csv of googlesheet data of random journals
  slice_head(n = 108) %>%
  select('journal' = 'journal_name', 'COPE' = 'COPE (T = member; F = not a member)' )

# Combine above CSVs to one tibble

dj_cope <- bind_rows(dj_prominent, dj_random)

# Identify duplicate rows
duplicates <- duplicated(dj_cope)

# Select the duplicate rows
duplicate_rows <- dj_cope[duplicates, ]

# Check if duplicate rows have the same COPE values for journals
for (i in seq_len(nrow(duplicate_rows))) {
  row <- duplicate_rows[i, ]
  id <- row$ID
  value <- row$Value
  same_values <- all(duplicate_rows$Value[duplicate_rows$ID == id] == value)
  
  if (same_values) {
    cat("Row", i, "with ID =", id, "has the same values in both columns.\n")
  } else {
    cat("Row", i, "with ID =", id, "has different values in both columns.\n")
  }
}

#All 14 duplicated (both sample) journals had consistent COPE status, join with main data tibble:
d_cope <- left_join(d_journals, dj_cope, by = 'journal')

```

#join() Code from checkData.RMD for importing JIFs and category


d_journals_prominent <- left_join(d_journals_prominent, journal_list_prominent_all, by = 'journal')

journal_list_random_all <- journal_list_random_all %>%
  select(journal = Journal, WOS_first_psych_category)

d_journals_random <- left_join(d_journals_random, journal_list_random_all, by = 'journal')

journal_list_prominent_all <- journal_list_prominent_all %>%
  select(-WOS_first_psych_category)
  
d_journals_random <- left_join(d_journals_random, journal_list_prominent_all, by = 'journal')

tmp <- d_journals_random %>% filter(is.na(`2021 JIF`)) %>% distinct(journal, .keep_all = T)
write_csv(tmp,here('data', 'prepareSample', 'journals', '02 - modified', 'we_need_jifs.csv'))



```

 
 

   
 
 