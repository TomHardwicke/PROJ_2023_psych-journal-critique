---
title: "Preprocessing"
output: html_document
date: "2023-08-21"
---

# Load packages 

```{r setup, include=FALSE}
library(tidyverse) # for various tasks including munging and plotting
library(here) # for easier file path access
library(tidylog) # for inline programming reporting
library(assertthat) # for testing
source(here('analysis','functions.R')) # load custom functions
```

# Convert raw data to primary data

This will be moved to master script later.

```{r}
source(here('analysis','raw_to_primary.R')) # converts raw data to primary data
```


# Load data

Load the extracted (i.e., manually coded) data.

```{r}
d_articles <- read_csv(here('data','primary','articles.csv'), show_col_types = F) # article data 
d_journals <- read_csv(here('data','primary','journals.csv'), show_col_types = F) # journal data 
```

# Rename colums 

Rename some columns for easier reference.

```{r}
d_journals <- d_journals %>%
  select(timestamps = Timestamp,
         sample_id,
         coder_id = `Coder's Initials`,
         journal = `Journal Name`,
         journal_empirical = `Does the journal publish empirical research?`,
         anyPPC = `Check the article types page and check for web comments — does the journal offer any type of PPC?`,
         A_ppc_name = `A. Enter the name of the PPC type offered by the journal:`,
         B_ppc_name = `B. Enter the name of the PPC type offered by the journal:`,
         C_ppc_name = `C. Enter the name of the PPC type offered by the journal:`,
         A_ppc_description = `A. Enter the verbatim description of this type of PPC provided by the journal`,
         B_ppc_description = `B. Enter the verbatim description of this type of PPC provided by the journal`,
         C_ppc_description = `C. Enter the verbatim description of this type of PPC provided by the journal`,
         A_ppc_length = `A. Are there any length limits for this type of PPC?`,
         B_ppc_length = `B. Are there any length limits for this type of PPC?`,
         C_ppc_length = `C. Are there any length limits for this type of PPC?`,
         A_ppc_time = `A. Are there any time limits for submission of this type of PPC?`,
         B_ppc_time = `B. Are there any time limits for submission of this type of PPC?`,
         C_ppc_time = `C. Are there any time limits for submission of this type of PPC?`,
         A_ppc_ref = `A. Are there any reference limits for this type of PPC?`,
         B_ppc_ref = `B. Are there any reference limits for this type of PPC?`,
         C_ppc_ref = `C. Are there any reference limits for this type of PPC?`,
         A_ppc_review = `A. Is this type of PPC sent for independent external peer review?`,
         B_ppc_review = `B. Is this type of PPC sent for independent external peer review?`,
         C_ppc_review = `C. Is this type of PPC sent for independent external peer review?`,
         A_ppc_note = `A. Anything additional, unusual, or interesting to note?`,
         B_ppc_note = `B. Anything additional, unusual, or interesting to note?`,
         C_ppc_note = `C. Anything additional, unusual, or interesting to note?`,
         general_note = `Anything additional, unusual, or interesting to note?`,
         cope, field, jif,
         -starts_with("D. "),
         -ends_with("Are there any other types of PPC in this journal? (Remember to check for web comments!)`"))

d_articles <- d_articles %>%
  select(
    sample_id,
    article_id = `article id`,
    coder_id_primary = `primary coder initials`,
    coder_id_secondary = `secondary coder initials`,
    exclusion_primary = `1_exclusion`,
    exclusion_reason_primary = `1_exclusionReason`,
    ppc_linked_primary = `1_Is article linked to PPC`,
    notes_primary = `1_Additional notes`,
    exclusion_secondary = `2_exclusion`,
    exclusion_reason_secondary = `2_exclusionReason`,
    ppc_linked_secondary = `2_Is article linked to PPC`,
    notes_secondary = `2_Additional notes`
  )
```

## Remove erroneous rows

Occasionally coders entered data for the same journal twice. Below we remove the erroneous rows, using the journal name and data entry timestamp to identify the relevant rows.

For the journal HUMAN ARENAS, RTT coded twice, first entry was an error and needs to be removed.

```{r}
d_journals <- d_journals %>%
  filter(!(journal == "HUMAN ARENAS" & timestamps == "8/6/2023 3:37:26" & coder_id != "FINAL (TEH)"))
```

For the journal INFANTS & YOUNG CHILDREN, MN coded twice, first entry was an error and needs to be removed.

```{r}
d_journals <- d_journals %>%
  filter(!(journal == "INFANTS & YOUNG CHILDREN" & timestamps == "7/15/2023 18:51:15" & coder_id != "FINAL (TEH)"))
```

For the journal EDUCATIONAL PSYCHOLOGIST, AW coded twice, first entry was an error and needs to be removed.

```{r}
d_journals <- d_journals %>%
  filter(!(journal == "EDUCATIONAL PSYCHOLOGIST" & timestamps == "6/29/2023 14:06:13" & coder_id != "FINAL (TEH)"))
```

For the journal EUROPEAN JOURNAL OF PERSONALITY, journal is in both samples so AW coded twice, entries are substantively the same, removing first entry.

```{r}
d_journals <- d_journals %>%
  filter(!(journal == "EUROPEAN JOURNAL OF PERSONALITY" & timestamps == "6/29/2023 22:01:35" & coder_id != "FINAL (TEH)"))
```

For the journal PERSONALITY AND SOCIAL PSYCHOLOGY REVIEW, two entries from NM, first entry was an error.

```{r}
d_journals <- d_journals %>%
  filter(!(journal == "PERSONALITY AND SOCIAL PSYCHOLOGY REVIEW" & timestamps == "7/3/2023 18:34:38" & coder_id != "FINAL (TEH)"))
```

For the journal PSYCHOLOGICAL MEDICINE, two entries from RTT, first entry was an error.

```{r}
d_journals <- d_journals %>%
  filter(!(journal == "PSYCHOLOGICAL MEDICINE" & timestamps == "8/6/2023 9:49:10" & coder_id != "FINAL (TEH)"))
```

# Perform initial tests and fix some issues

Let's check a few columns to see if they contain what we expect.

## Journal data initial tests

Check we have the expected coder initials in `coder_id` and convert column to factor.

```{r}
expected_coders <- c("AW", "NM", "SV", "RTT", "TEH", "SS", "BC", "FINAL (TEH)")

assert_that(
  all(d_journals$coder_id %in% expected_coders),
  msg = "Found unexpected values in the coder_id column"
)

d_journals$coder_id = factor(d_journals$coder_id) # make this column a factor
```

Check every row has a `journal`. 

```{r}
assert_that(
  all(!is.na(d_journals$journal)),
  msg = "Found missing journal name"
)
```

We can't run any more useful tests at this point because in many columns coders have used entered free text to explain cases that were unclear. So we will run tests again later after coding discrepancies have been resolved.

## Articles data initial tests

Check every row has an entry in `article_id`.

```{r}
assert_that(
  all(!is.na(d_articles$article_id)),
  msg = "Found missing article ids"
)
```

Check we have the expected coder initials in `coder_id_primary` and `coder_id_secondary` columns and convert columns to factor.

```{r}
assert_that(
  all(d_articles$coder_id_primary %in% expected_coders),
  msg = "Found unexpected values in the coder_id_primary column"
)

assert_that(
  all(d_articles$coder_id_secondary %in% expected_coders),
  msg = "Found unexpected values in the coder_id_primary column"
)

# make these columns factors
d_articles$coder_id_primary = factor(d_articles$coder_id_primary)
d_articles$coder_id_secondary = factor(d_articles$coder_id_secondary)

```

Now check we only have expected values in the `exclusion_primary` column.

```{r}
assert_that(
  all(d_articles$exclusion_primary %in% c("RETAIN", "EXCLUDE")),
  msg = "Found unexpected values in the exclusion_primary column"
)
```
Now check we only have expected values in the `exclusion_secondary` column.

```{r}
assert_that(
  all(d_articles$exclusion_secondary %in% c("RETAIN", "EXCLUDE")),
  msg = "Found unexpected values in the exclusion_primary column"
)
```

# Articles data — Resolve coding disagreements

Find cases where primary and secondary coder disagreed on whether to exclude.

```{r}
# NOT RUN — used to identify cases where primary and secondary coder disagreed on whether to exclude.
 # d_articles %>%
 #    filter(exclusion_primary != exclusion_secondary)
```

Following protocol, coding discrepancies are resolved by TEH. We now create an `exclusion_final` column which represents the resolved coding. TEH decides to either go with the primary or secondary coder's verdict. For other articles, we use the primary coder's verdict (which is the same as the secondary coder).

```{r}
# create exclusion_final column
d_articles <- d_articles %>%
  mutate(exclusion_final = case_when(
    sample_id == 'random' & article_id == '37' ~ exclusion_primary,
    sample_id == 'random' & article_id == '41' ~ exclusion_primary,
    sample_id == 'random' & article_id == '68' ~ exclusion_secondary,
    sample_id == 'random' & article_id == '95' ~ exclusion_secondary,
    sample_id == 'random' & article_id == '103' ~ exclusion_primary,
    sample_id == 'random' & article_id == '120' ~ exclusion_primary,
    sample_id == 'prominent' & article_id == '30' ~ exclusion_secondary,
    sample_id == 'prominent' & article_id == '49' ~ exclusion_primary,
    sample_id == 'prominent' & article_id == '66' ~ exclusion_primary,
    sample_id == 'prominent' & article_id == '98' ~ exclusion_primary,
    sample_id == 'prominent' & article_id == '123' ~ exclusion_primary,
    sample_id == 'prominent' & article_id == '124' ~ exclusion_primary,
    sample_id == 'prominent' & article_id == '130' ~ exclusion_secondary,
    sample_id == 'prominent' & article_id == '132' ~ exclusion_primary,
    TRUE ~ exclusion_primary
  ))

# create exclusion_reason_final column
d_articles <- d_articles %>%
  mutate(exclusion_reason_final = case_when(
    sample_id == 'random' & article_id == '37' ~ exclusion_reason_primary,
    sample_id == 'random' & article_id == '41' ~ exclusion_reason_primary,
    sample_id == 'random' & article_id == '68' ~ exclusion_reason_secondary,
    sample_id == 'random' & article_id == '95' ~ exclusion_reason_secondary,
    sample_id == 'random' & article_id == '103' ~ exclusion_reason_primary,
    sample_id == 'random' & article_id == '120' ~ exclusion_reason_primary,
    sample_id == 'prominent' & article_id == '30' ~ exclusion_reason_secondary,
    sample_id == 'prominent' & article_id == '49' ~ exclusion_reason_primary,
    sample_id == 'prominent' & article_id == '66' ~ exclusion_reason_primary,
    sample_id == 'prominent' & article_id == '98' ~ exclusion_reason_primary,
    sample_id == 'prominent' & article_id == '130' ~ exclusion_reason_secondary,
    TRUE ~ exclusion_reason_primary
  ))
```

Find cases where primary and secondary coder disagreed on why to exclude.

```{r}
# we've already dealt with cases where the decision to exclude differs, so we're not looking only at cases where the decision to exclude matches, but the reason for exclusion differs
 # d_articles %>% # NOT RUN
 #   filter(exclusion_primary == exclusion_secondary, 
 #          exclusion_reason_primary != exclusion_reason_secondary) %>%
 #   select(article_id, sample_id, exclusion_reason_primary, exclusion_reason_secondary, exclusion_reason_final)
```

We will resolve these by applying the exclusion criteria hierarchically. In other words, we use the highest level of exclusion criteria assigned by one of the two coders.
1. Access
2. English
3. Retracted 
4. Non-empirical

```{r}
# update exclusion_reason_final column when primary and secondary coder disagree on reason to exclude.
d_articles <- d_articles %>%
  mutate(exclusion_reason_final = case_when(
    sample_id == 'random' & article_id == '14' ~ exclusion_reason_primary,
    sample_id == 'random' & article_id == '35' ~ exclusion_reason_primary,
    sample_id == 'random' & article_id == '54' ~ exclusion_reason_secondary,
    sample_id == 'random' & article_id == '73' ~ exclusion_reason_primary,
    sample_id == 'random' & article_id == '78' ~ exclusion_reason_primary,
    sample_id == 'prominent' & article_id == '29' ~ "RETRACTED", # the article was withdrawn, retracted seems like the closest fit among out labels
    sample_id == 'prominent' & article_id == '37' ~ exclusion_reason_primary,
    sample_id == 'prominent' & article_id == '39' ~ exclusion_reason_primary,
    sample_id == 'prominent' & article_id == '46' ~ exclusion_reason_primary,
    sample_id == 'prominent' & article_id == '54' ~ exclusion_reason_secondary,
    TRUE ~ exclusion_reason_final # if none of the above, retain whatever is in this column already
  ))
```

Finally, let's check anything that was excluded with the reason "OTHER". 

```{r}
d_articles %>% 
  filter(exclusion_reason_final == "OTHER") %>% 
  select(article_id, sample_id)
```

Article ID 68 can reclassifed as "NO ACCESS" and for the other three articles we can create a new post-hoc exclusion category "CONFERENCE ABSTRACT".

```{r}
d_articles <- d_articles %>%
  mutate(exclusion_reason_final = case_when(
    sample_id == 'random' & article_id == '68' ~ "NO ACCESS",
    sample_id == 'prominent' & article_id == '2' ~ "CONFERENCE ABSTRACT",
    sample_id == 'prominent' & article_id == '56' ~ "CONFERENCE ABSTRACT",
    sample_id == 'prominent' & article_id == '85' ~ "CONFERENCE ABSTRACT",
    TRUE ~ exclusion_reason_final # if none of the above, retain whatever is in this column already
  ))
```

We should now have resolved coding for all exclusion decisions and exclusion reasons in d_articles

```{r}
d_articles %>%
  group_by(sample_id) %>%
  count(exclusion_final, exclusion_reason_final) %>%
  ungroup()
```

Now for articles that are retained, we need to check if they have the same classification in `ppc_linked`.

```{r}
d_articles %>%
  filter(exclusion_final == "RETAIN",
         ppc_linked_primary != ppc_linked_secondary)
```

There appears to be one case where the primary coder did not identify any PPC links, but the secondary coder did. After review, TEH determines that there is a linked PPC for this article. Thus for this article, the final coding is the same as the secondary coder's classification, and for all other articles we use the primary coder's classification (which is the same as the secondary coders in those cases).

```{r}
d_articles <- d_articles %>%
  mutate(ppc_linked_final = case_when(
    exclusion_final == "EXCLUDE" ~ NA_character_, # if article is excluded, use NA
    sample_id == 'prominent' & article_id == '38' ~ ppc_linked_secondary,
    exclusion_final == "RETAIN" & exclusion_primary == "RETAIN" ~ ppc_linked_primary,
    exclusion_final == "RETAIN" & exclusion_secondary == "RETAIN" ~ ppc_linked_secondary,
    TRUE ~ "ERROR" # if none of the above, retain whatever is in this column already
  ))
```

# Journals data — Resolve coding disagreements

Note — its easier to do this in the original spreadsheet — for each journal I've added a new row with coder initials "FINAL (TEH)". If primary and secondary coding are aligned I just copied their coding into this row. If there were differences, I resolved them and entered the final decision into the new row.

Retain only the final coding for journals.

```{r}
d_journals <- d_journals %>%
  filter(coder_id == "FINAL (TEH)") %>% # select only the final coding
  select(-coder_id, -timestamps) # drop the coder_id and timestamps columns
```

# Journals data — reorganise

Currently we have one row per journal, and sometimes more than one PPC per journal. To make analysis easier, let's switch the data frame from wide to long format (i.e., switch to one row per PPC instead of one row per journal).

```{r}
d_journals <- d_journals %>%
  pivot_longer( # pivot to long format
    cols = c(-journal,-journal_empirical, -sample_id,-anyPPC,-general_note, -cope, -field, -jif),
    names_to = c("PPC_type", ".value"), 
    names_sep = "_ppc_"
  )
```

# Journals data — Harmonization 

## Harmonize length limits

Journals used different units to report length limits (e.g., pages, lines, characters, words). We will convert these various units to words using the following approximations.

```{r}
pageToWord <- 500 # using our own recent papers as a guide, we estimate one page to be approximately 500 words. Thus, any limits stated with page units need to be multiplied by 500 to convert to words
charToWord <- 6 # using our own recent papers as a guide, we estimate an average of 6 characters per word. Thus, any limits stated with character units need to be divided by 6 to convert to words
linesToWord <- 10 # after inspecting articles published by journals that use line units, we estimate an average of 10 words per line. Thus any limits stated with line units need to be multiplied by ten to convert to words
```

We will also harmonize differences in data entry formatting, e.g., some coders used quotation marks, commas etc. Any qualitative limits will be designated as such.

```{r}
d_journals <- d_journals %>% 
  mutate(length_harmonized = str_remove_all(length, pattern = '"'), #  remove any quotation marks
         length_harmonized = str_remove(length_harmonized, pattern = fixed("YES (copy and paste the limits in the 'other' section below), ")),# remove data entry question text
         length_harmonized = case_when(
           length_harmonized == "1,000 words" ~ "1000",
           length_harmonized == "1,500 words (one figure and/or one table allowed within word count)" ~ "1500",
           length_harmonized == "1000 words" ~ "1000",
           length_harmonized == "16 pages" ~ as.character(16*pageToWord),
           length_harmonized == "2000 words" ~ "2000",
           length_harmonized == "265 lines of text including references" ~ as.character(265*linesToWord),
           length_harmonized == "3500 words (title page and references included)" ~ "3500",
           length_harmonized == "400 words" ~ "400",
           length_harmonized == "5 pages, including abstract, references, tables, and figures." ~ as.character(5*pageToWord),
           length_harmonized == "500 words" ~ "500",
           length_harmonized == "600-800 words" ~ "800",
           length_harmonized == "750 words" ~ "750",
           length_harmonized == "Approx. 1,000 words" ~ "1000",
           length_harmonized == "approximately 1,000 words" ~ "1000",
           length_harmonized == "as concise as possible, and ideally not exceed 1,200 words" ~ "1200",
           length_harmonized == "at maximum half the length of the target article." ~ "Qualitative",
           length_harmonized == "Maximum length: 1100 words." ~ "1100",
           length_harmonized == "short" ~ "Qualitative",
           length_harmonized == "up to 2,000 words counting 500 words per table and figure" ~ "2000",
           length_harmonized == " Rebuttals and peer commentaries should not exceed 1000 words. Exceptions to these length guidelines can be granted in special cases." ~ "1000",
           length_harmonized == "1,200 words" ~ "1200",
           length_harmonized == "1200 words (main text)" ~ "1200",
           length_harmonized == "2,000 words (excluding abstract, references). Abstract: 200 words" ~ "2000",
           length_harmonized == "5 pages" ~ as.character(5*pageToWord),
           length_harmonized == "no more than 1000 words" ~ "1000",
           length_harmonized == "no more than half the length of the original article" ~ "Qualitative",
           length_harmonized == "not exceed 500 words" ~ "500",
           length_harmonized == "Such manuscripts should normally be between 3,000 to 5,000 words, all inclusive (i.e., abstract, text, figures, tables, and references)." ~ "5000",
           length_harmonized == "typically 1,500 words, excluding references.​" ~ "1500",
           length_harmonized == "up to 3,000 words" ~ "3000",
           length_harmonized == "3000 words" ~ "3000",
           length_harmonized == "1500 words" ~ "1500",
           TRUE ~ length_harmonized
         )) 
```

## Harmonize time-to-submit limits

Journals used different units to report time limits (e.g., weeks, months, years). We will convert these various units to weeks using the following approximations.

```{r}
monthToWeek <- 4.35 # number to multiply months by to get weeks
yearToWeek <- 52 # number to multiply years by to get weeks
```

We will also harmonize differences in data entry formatting, e.g., some coders used quotation marks, commas etc. Any qualitative limits will be designated as such.

```{r}
d_journals <- d_journals %>% 
  mutate(time_harmonized = str_remove_all(time, pattern = '"'), #  remove any quotation marks
         time_harmonized = str_remove(time_harmonized, pattern = fixed("YES (provide detail of time limits below), ")),# remove data entry question text
         time_harmonized = case_when(
           time_harmonized == "3 months" ~ as.character(3*monthToWeek),
           time_harmonized == "6 months" ~ as.character(6*monthToWeek),
           time_harmonized == "9 months" ~ as.character(9*monthToWeek),
           time_harmonized == "Draft proposed comments will be due on a tight time- line (i.e., 2– 4 weeks after solicitation), to be determined by the Editor." ~ "4",
           time_harmonized == "he Commentary mechanism is most effective when used to address a contemporary publication" ~ "Qualitative",
           time_harmonized == "Matters Arising articles are interesting and timely scientific or academic comments" ~ "Qualitative",
           time_harmonized == "recent" ~ "Qualitative",
           time_harmonized == "timely" ~ "Qualitative",
           time_harmonized == "UNCLEAR (provide detail in the 'other' section below), timely scientific comments" ~ "Qualitative",
           time_harmonized == "recently published" ~ "Qualitative",
           time_harmonized == "UNCLEAR (provide detail in the 'other' section below), recently published" ~ "Qualitative",
           time_harmonized == "YES (copy and paste the limits in the 'other' section below), 1-year (except for a test of replication)" ~ as.character(1*yearToWeek),
           TRUE ~ time_harmonized
         )) 
```

## Harmonize reference limits

For reference limits we need to harmonize differences in data entry formatting. Additionally, when references are included in the overall length limit, we will re-code these as "NOT STATED", because no specific reference limit has been stated.

```{r}
d_journals <- d_journals %>% 
  mutate(ref_harmonized = str_remove_all(ref, pattern = '"'), #  remove any quotation marks
         ref_harmonized = str_remove(ref_harmonized, pattern = fixed("YES (provide number of references below), ")),# remove data entry question text
         ref_harmonized = str_remove(ref_harmonized, pattern = fixed("YES (copy and paste the limits in the 'other' section below), ")),# remove data entry question text
         ref_harmonized = case_when(
           ref_harmonized == "20 not hard-and-fast limits" ~ "20",
           ref_harmonized == "265 lines of text including references" ~ "NOT STATED",
           ref_harmonized == "contributions may have up to 15 references" ~ "15",
           ref_harmonized == "Included in 16 page overall limit" ~ "NOT STATED",
           ref_harmonized == "No more than 5 references" ~ "5",
           ref_harmonized == "a maximum of 5 references" ~ "5",
           ref_harmonized == "max 20" ~ "20",
           ref_harmonized == "overall limit is 265 lines of text including references" ~ "NOT STATED",
           TRUE ~ ref_harmonized
         )) 
```

## Harmonize peer review policies

For PPC peer review policy we need to harmonize differences in data entry formatting. 

```{r}
d_journals <- d_journals %>% 
  mutate(review_harmonized = str_remove_all(review, pattern = '"'), #  remove any quotation marks
         review_harmonized = case_when(
           review == "NO, This correspondence is published at the discretion of the Editor-in-Chief and the Associate Editors" ~ "NO",
           review == "NOT STATED, The guidelines discuss peer review, but it appears that this discussion isn't relevant to commentary articles." ~ "NOT STATED",
           review == "UNCLEAR (provide detail in the 'other' section below), It 'may' be sent for independent review: 'Matters Arising submissions that meet the journal’s criteria are sent to the authors of the original paper for a formal response. The comments and formal response may then be sent to independent referees.'" ~ "YES",
           review == "NO, Strongly implied not, by this: \"The decision to publish is made by the Editors, in order to ensure a timely appearance in print. \"" ~ "NO",
           review == "YES, ...published work and may, after peer review, be published online as Matters Arising" ~ "YES",
           review == "YES, Commentaries will be subjected to peer-review and will be held to the same standards of providing a notable contribution to our field to warrant publication." ~ "YES",
           TRUE ~ review
         )) 
```

## Harmonize PPC names

Currently the PPC names are copied verbatim from the journal websites but many of them are basically the same name with small grammatical differences (e.g., letters, letter to the editor etc.). For analysis, we need to harmonize these names.

Firstly, we will harmonize names that are grammatically similar. We will then examine conceptual similarity and see if we can summarise the types into a few high level categories. A guiding assumption here is that we can capture most PPC types with three categories (based on personal experience and empirical data, Hardwicke et al. 2022):

* letters to the editor - tend to be shorter articles
* commentaries - tend to be longer articles
* web comments - tend be to be short informal comments, usually appearing below articles on the journal website

If PPCs we have identified clearly do not fit into these categories, we will categorize them as "OTHER". 

Firstly, specify PPC names that we want to convert to different harmonized names.

```{r}
commentaries <- c("Brief comment", "Brief Comment", "Brief empirical notes", "brief peer commentaries or rebuttals", "commentaries", "Commentaries", "Commentary", "Comments", "Commentry", "commentary", "Commentary articles", "Matters Arising", "Observations & Commentaries", "Open peer commentaries", "Short Communications and Commentaries", "Short Research Notes", "Text review")
letters <- c("Letter", "Letters", "Letter to the editor", "Letters to the editor", "letters to the editor", "Letters to the Editor.", "letters to the editors", "Letters to the Editors", "Letters to the Editor", "Letter to the Editor", "Responses", "Correspondence")
# web_comments <- c()
other <- c("Verification reports")
```

```{r}
d_journals <- d_journals %>%
  mutate(name_harmonized = case_when(
    name %in% commentaries ~ "Commentary",
    name %in% letters ~ "Letters",
    name %in% other ~ "Other"
  ))
```
# Harmonize field names deferring to WoS category
```{r}

d_journals <- d_journals %>% 
  mutate(field_harmonized = case_when(
           field == "Psychology | Sport" ~ "Sport",
           field == "Psychology, Applied" ~ "Applied",
           field == "PSYCHOLOGY, APPLIED" ~ "Applied",
           field == "Psychology, Biological" ~ "Biological",
           field == "PSYCHOLOGY, BIOLOGICAL" ~ "Biological",
           field == "Psychology, Clinical" ~ "Clinical",
           field == "PSYCHOLOGY, CLINICAL" ~ "Clinical",
           field == "Psychology, Development" ~ "Developmental",
           field == "PSYCHOLOGY, DEVELOPMENTAL" ~ "Developmental",
           field == "Psychology, Educational" ~ "Educational",
           field == "PSYCHOLOGY, EDUCATIONAL" ~ "Educational",
           field == "Psychology, Experimental" ~ "Experimental",
           field == "PSYCHOLOGY, EXPERIMENTAL" ~ "Experimental",
           field == "Psychology, Mathematical" ~ "Mathematical",
           field == "Psychology, Multidisciplinary" ~ "Multidisciplinary",
           field == "PSYCHOLOGY, MULTIDISCIPLINARY" ~ "Multidisciplinary",
           field == "Psychology, Social" ~ "Social",
           field == "PSYCHOLOGY, SOCIAL" ~ "Social",
           field == "Psychology" ~ "General",
           field == "PSYCHOLOGY - SCIE" ~ "General",
           TRUE ~ field
         )) 

```

# Reclassify and reformat

Reclassify some values like "Yes" and "No" into logicals, format some columns, and select only columns we need for data analysis.

```{r}
d_journals <- d_journals %>%
  mutate(sample_id = factor(sample_id),
         journal_name = factor(journal),
         is_empirical = as.logical(fct_recode(journal_empirical, T = "Yes", F = "No")),
         has_ppc = fct_recode(anyPPC, 
                             "ARCHIVE" = "ARCHIVE ONLY", 
                             "NO IMPLICIT" = "NO (there are no PPC options)",
                             "NO EXPLICIT" = "NO (explicit statement that PPC is not accepted)")) %>%
  select(sample_id, journal_name, is_empirical, has_ppc, ppc_type = PPC_type, ppc_name = name_harmonized, ppc_description = description, ppc_length = length_harmonized, ppc_time = time_harmonized, ppc_ref = ref_harmonized, ppc_review = review_harmonized, cope, field = field_harmonized, jif)
```
#Reclassify PPC name in JOURNAL OF CLINICAL PSYCHIATRY due to quotation marks in raw data name impeding inclusion above

```{r}
d_journals <- d_journals %>%
  mutate(ppc_name = ifelse(is.na(ppc_name) & journal_name == "JOURNAL OF CLINICAL PSYCHIATRY" & ppc_type == "A", "Letters", ppc_name))
```

```{r}
d_articles <- d_articles %>%
  mutate(sample_id = factor(sample_id),
         article_id = factor(article_id),
         exclude = factor(exclusion_final),
         exclude_reason = factor(exclusion_reason_final),
         ppc_linked = as.logical(fct_recode(ppc_linked_final, T = "NO", F = "YES"))) %>%
  select(sample_id, article_id, exclude, exclude_reason, ppc_linked)
```

# Final tests

We'll run some final tests in this section to make sure we have what we expect in each column.

Now check that `journal_empirical` contains only 'Yes' or 'No'. When we first run the test we get unexpected values.

and convert these to `TRUE` and `FALSE` respectively.

```{r}
assert_that(
  all(d_journals$is_empirical %in% c(T,F)),
  msg = "Found unexpected values in is_empirical column"
)
```

Now check that when `exclusion_primary` and `exclusion_secondary` are "EXCLUDE" then we have reasons in the reason columns. When they are "RETAIN" the reason columns should be NA.

```{r}
# primary_exclusions <- d_articles %>% 
#   count(exclusion_primary, exclusion_reason_primary) %>%
#   mutate(expected_values = case_when(
#     exclusion_primary == "RETAIN" & is.na(exclusion_reason_primary) ~ T,
#     exclusion_primary == "EXCLUDE" & exclusion_reason_primary %in% c("NO ACCESS", "NON-ENGLISH", "NOT EMPIRICAL", "RETRACTED", "IS ITSELF PPC", "OTHER") ~ T,
#     TRUE ~ "criteria not met"
#   ))
# 
# secondary_exclusions <- d_articles %>% 
#   count(exclusion_secondary, exclusion_reason_secondary) %>%
#   
# 
# 
# assert_that(, msg = "Found unexpected value in exclusion reason column when it should be NA")
```

# Export files to processed data folder

The data is now ready for analysis! Let's export it to the 'processed' data folder.

```{r}
write_csv(d_articles, here('data','processed','d_articles.csv'))
write_csv(d_journals, here('data','processed','d_journals.csv'))
```


