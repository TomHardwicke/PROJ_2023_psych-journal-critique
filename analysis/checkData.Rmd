---
title: "checkData"
output: html_document
date: "2023-08-21"
---

# Load packages 

```{r setup, include=FALSE}
library(tidyverse) # for various tasks including munging and plotting
library(here) # for easier file path access
library(tidylog) # for inline programming reporting
library(assertthat) # for testing
`%notin%` <- Negate(`%in%`) # for identifying when values are not in a vector of expected values
```

# Load data

Load the extracted (i.e., manually coded) data.

```{r}
# article data (random)
d_articles_random <- read_csv(here('data','raw','articles (random) - Sheet1.csv'), show_col_types = F) %>%
  filter(!is.na(`primary coder initials`) & !is.na(`secondary coder initials`)) # we only need articles that were coded by someone

# article data (prominent)
d_articles_prominent <- read_csv(here('data','raw','articles (prominent) - Sheet1.csv'), show_col_types = F)  %>%
  filter(!is.na(`primary coder initials`) & !is.na(`secondary coder initials`)) # we only need articles that were coded by someone

# journal data (random and prominent sample)
d_journals <- read_csv(here('data','raw','Data Extraction Form (policy) (Responses) - Form Responses 1.csv'), show_col_types = F)
```

There is some information about the sample that isn't included in the extracted data files (e.g., JIFs, Web of Science subject category), so we need to load some of that information from the original sample files.

```{r}
# list of journals in random sample
journal_list_random <- read_csv(here('data','prepareSample','journals', '03 - final', 'journals-random.csv'), show_col_types = F) %>%
  slice_head(n = 108) %>%
  select(`Journal`)

# list of journals in prominent sample
journal_list_prominent <- read_csv(here('data','prepareSample','journals', '03 - final', 'journals-prominent.csv'), show_col_types = F) %>%
  slice_head(n = 114) %>%
  select('Journal' = `Journal name`)

# list of all prominent journals (some not in sample)
journal_list_prominent_all <- read_csv(here('data','prepareSample','journals', '03 - final', 'journals-prominent.csv'), show_col_types = F)

# list of all random journals (some not in sample)
journal_list_random_all <- read_csv(here('data','prepareSample','journals', '03 - final', 'journals-random.csv'), show_col_types = F)
```

# Rename colums 

Rename some columns for easier reference.

```{r}
d_journals <- d_journals %>%
  select(timestamps = Timestamp,
         coder_id = `Coder's Initials`,
         pilot = `Are you piloting?`,
         journal = `Journal Name`,
         journal_empirical = `Does the journal publish empirical research?`,
         anyPPC = `Check the article types page and check for web comments â€” does the journal offer any type of PPC?`,
         A_ppc_name = `A. Enter the name of the PPC type offered by the journal:`,
         B_ppc_name = `B. Enter the name of the PPC type offered by the journal:`,
         C_ppc_name = `C. Enter the name of the PPC type offered by the journal:`,
         A_ppc_description = `A. Enter the verbatim description of this type of PPC provided by the journal`,
         B_ppc_description = `B. Enter the verbatim description of this type of PPC provided by the journal`,
         C_ppc_description = `C. Enter the verbatim description of this type of PPC provided by the journal`,
         A_ppc_length = `A. Are there any length limits for this type of PPC?`,
         B_ppc_length = `B. Are there any length limits for this type of PPC?`,
         C_ppc_length = `C. Are there any length limits for this type of PPC?`,
         A_ppc_time = `A. Are there any time limits for submission of this type of PPC?`,
         B_ppc_time = `B. Are there any time limits for submission of this type of PPC?`,
         C_ppc_time = `C. Are there any time limits for submission of this type of PPC?`,
         A_ppc_ref = `A. Are there any reference limits for this type of PPC?`,
         B_ppc_ref = `B. Are there any reference limits for this type of PPC?`,
         C_ppc_ref = `C. Are there any reference limits for this type of PPC?`,
         A_ppc_review = `A. Is this type of PPC sent for independent external peer review?`,
         B_ppc_review = `B. Is this type of PPC sent for independent external peer review?`,
         C_ppc_review = `C. Is this type of PPC sent for independent external peer review?`,
         A_ppc_note = `A. Anything additional, unusual, or interesting to note?`,
         B_ppc_note = `B. Anything additional, unusual, or interesting to note?`,
         C_ppc_note = `C. Anything additional, unusual, or interesting to note?`,
         general_note = `Anything additional, unusual, or interesting to note?`,
         -starts_with("D. "), 
         -ends_with("Are there any other types of PPC in this journal? (Remember to check for web comments!)`"))

d_articles_random <- d_articles_random %>%
  select(
    article_id = `article id`,
    coder_id_primary = `primary coder initials`,
    coder_id_secondary = `secondary coder initials`,
    exclusion_primary = `1_exclusion`,
    exclusion_reason_primary = `1_exclusionReason`,
    ppc_linked_primary = `1_Is article linked to PPC`,
    notes_primary = `1_Additional notes`,
    exclusion_secondary = `2_exclusion`,
    exclusion_reason_secondary = `2_exclusionReason`,
    ppc_linked_secondary = `2_Is article linked to PPC`,
    notes_secondary = `2_Additional notes`
  )

d_articles_prominent <- d_articles_prominent %>%
  select(
    article_id = `article id`,
    coder_id_primary = `primary coder initials`,
    coder_id_secondary = `secondary coder initials`,
    exclusion_primary = `1_exclusion`,
    exclusion_reason_primary = `1_exclusionReason`,
    ppc_linked_primary = `1_Is article linked to PPC`,
    notes_primary = `1_Additional notes`,
    exclusion_secondary = `2_exclusion`,
    exclusion_reason_secondary = `2_exclusionReason`,
    ppc_linked_secondary = `2_Is article linked to PPC`,
    notes_secondary = `2_Additional notes`
  )
```

# Remove non-relevant rows

## Remove pilot journals

Removing all rows that were entered during piloting and therefore not part of the main sample.

```{r}
d_journals <- d_journals %>%
  filter(pilot == "No") %>%
  select(-pilot)
```

## Remove erroneous rows

Occasionally coders entered data for the same journal twice. Below we remove the erroneous rows, using the journal name and data entry timestamp to identify the relevant rows.

For the journal HUMAN ARENAS, RTT coded twice, first entry was an error and needs to be removed.

```{r}
d_journals <- d_journals %>%
  filter(!(journal == "HUMAN ARENAS" & timestamps == "8/6/2023 3:37:26"))
```

For the journal INFANTS & YOUNG CHILDREN, MN coded twice, first entry was an error and needs to be removed.

```{r}
d_journals <- d_journals %>%
  filter(!(journal == "INFANTS & YOUNG CHILDREN" & timestamps == "7/15/2023 18:51:15"))
```

For the journal EDUCATIONAL PSYCHOLOGIST, AW coded twice, first entry was an error and needs to be removed.

```{r}
d_journals <- d_journals %>%
  filter(!(journal == "EDUCATIONAL PSYCHOLOGIST" & timestamps == "6/29/2023 14:06:13"))
```

For the journal EUROPEAN JOURNAL OF PERSONALITY, journal is in both samples so AW coded twice, entries are substantively the same, removing first entry.

```{r}
d_journals <- d_journals %>%
  filter(!(journal == "EUROPEAN JOURNAL OF PERSONALITY" & timestamps == "6/29/2023 22:01:35"))
```

For the journal PERSONALITY AND SOCIAL PSYCHOLOGY REVIEW, two entries from NM, first entry was an error.

```{r}
d_journals <- d_journals %>%
  filter(!(journal == "PERSONALITY AND SOCIAL PSYCHOLOGY REVIEW" & timestamps == "7/3/2023 18:34:38"))
```

For the journal PSYCHOLOGICAL MEDICINE, two entries from RTT, first entry was an error.

```{r}
d_journals <- d_journals %>%
  filter(!(journal == "PSYCHOLOGICAL MEDICINE" & timestamps == "8/6/2023 9:49:10"))
```

# Perform initial tests and fix issues

Let's check a few columns to see if they contain what we expect.

## Journals

Check we have the expected coder initials in `coder_id` and convert column to factor.

```{r}
expected_coders <- c("AW", "NM", "SV", "RTT", "TEH", "SS", "BC", "FINAL (TEH)")

assert_that(
  all(d_journals$coder_id %in% expected_coders),
  msg = "Found unexpected values in the coder_id column"
)

d_journals$coder_id = factor(d_journals$coder_id) # make this column a factor
```

Check every row has a `journal`. 

```{r}
assert_that(
  all(!is.na(d_journals$journal)),
  msg = "Found missing journal name"
)
```

Check every row has a `journal` that appears in the original random or prominent sample lists. We initially get an error for this test because some journal names were entered in the extraction form with incorrect formatting. Correct this below before running the test.

```{r}
d_journals <- d_journals %>% 
  mutate(journal = fct_recode(journal,
                              "MEMORY & COGNITION" = "Memory & Cognition","JOURNAL OF COUPLE & RELATIONSHIP THERAPY-INNOVATIONS IN CLINICAL AND EDUCATIONAL INTERVENTIONS" = "Journal of Couple & Relationship Therapy"))
```

```{r}
assert_that(
  all(d_journals$journal %in% c(journal_list_prominent$Journal, journal_list_random$Journal)),
  msg = "Found journal names that do not match sample"
)
```

That fixed the problem, now all journal names in the extracted data match journal names in the sample files.

We can't run any more useful tests at this point because in many columns coders have used entered free text to explain cases that were unclear. So we will run tests again later after coding discrepancies have been resolved.

## Articles

Firstly let's join the prominent and random articles together (with a new column identifying which sample they are in) to streamline some testing.

```{r}
d_articles <- bind_rows(
  d_articles_random %>% mutate(sampleID = "random"),
  d_articles_prominent %>% mutate(sampleID = "prominent")
)
```

Check every row has an entry in `article_id`.

```{r}
assert_that(
  all(!is.na(d_articles$article_id)),
  msg = "Found missing article ids"
)
```

Check we have the expected coder initials in `coder_id_primary` and `coder_id_secondary` columns and convert columns to factor.

```{r}
assert_that(
  all(d_articles$coder_id_primary %in% expected_coders),
  msg = "Found unexpected values in the coder_id_primary column"
)

assert_that(
  all(d_articles$coder_id_secondary %in% expected_coders),
  msg = "Found unexpected values in the coder_id_primary column"
)

# make these columns factors
d_articles$coder_id_primary = factor(d_articles$coder_id_primary)
d_articles$coder_id_secondary = factor(d_articles$coder_id_secondary)

```

Now check we only have expected values in the `exclusion_primary` column.

```{r}
assert_that(
  all(d_articles$exclusion_primary %in% c("RETAIN", "EXCLUDE")),
  msg = "Found unexpected values in the exclusion_primary column"
)
```
Now check we only have expected values in the `exclusion_secondary` column.

```{r}
assert_that(
  all(d_articles$exclusion_secondary %in% c("RETAIN", "EXCLUDE")),
  msg = "Found unexpected values in the exclusion_primary column"
)
```

Now check that when `exclusion_primary` and `exclusion_secondary` are "EXCLUDE" then we have reasons in the reason columns. When they are "RETAIN" the reason columns should be NA.

```{r}
# primary_exclusions <- d_articles %>% 
#   count(exclusion_primary, exclusion_reason_primary) %>%
#   mutate(expected_values = case_when(
#     exclusion_primary == "RETAIN" & is.na(exclusion_reason_primary) ~ T,
#     exclusion_primary == "EXCLUDE" & exclusion_reason_primary %in% c("NO ACCESS", "NON-ENGLISH", "NOT EMPIRICAL", "RETRACTED", "IS ITSELF PPC", "OTHER") ~ T,
#     TRUE ~ "criteria not met"
#   ))
# 
# secondary_exclusions <- d_articles %>% 
#   count(exclusion_secondary, exclusion_reason_secondary) %>%
#   
# 
# 
# assert_that(, msg = "Found unexpected value in exclusion reason column when it should be NA")
```


# Attach sample information to extracted data

## Identify sample for journals

The `d_journals` dataset does not identify whether journals were in the prominent sample, random sample, or both. So we need to get the sample ID retroactively using the files containing all journals included in the sample.

Create sample ID column(s) to indicate whether in prominent, random, or both samples

```{r}
d_journals <- d_journals %>%
  mutate(
    sample_journal_prominent = journal %in% journal_list_prominent$Journal,
    sample_journal_random = journal %in% journal_list_random$Journal,
    sample_journal_both = sample_journal_prominent & sample_journal_random,
    sample_journal_error = !sample_journal_prominent & !sample_journal_random
  )

#Creates sampleID column denoting; prominent, random, or both to replace the 4 specified columns above
d_journals <- d_journals %>% 
  mutate(sample_journal_prominent = ifelse(sample_journal_prominent, "prominent", "random")) %>%
  mutate(sample_journal_both = ifelse(sample_journal_both, "both", "na")) %>%
  mutate(sampleID = case_when(
    sample_journal_both == "both" ~ "both",
    sample_journal_both == "na" ~ sample_journal_prominent,
    TRUE ~ sample_journal_both
  )) %>%
  select(-c(sample_journal_prominent, sample_journal_random, sample_journal_both, sample_journal_error))
```

## Identify JIFs for journals

```{r}
d_journals_prominent <- d_journals %>%
  filter(sampleID %in% c('prominent', 'both'))

d_journals_random <- d_journals %>%
  filter(sampleID == 'random')

journal_list_prominent_all <- journal_list_prominent_all %>% 
  select(journal = `Journal name`, `2021 JIF`, WOS_first_psych_category)

d_journals_prominent <- left_join(d_journals_prominent, journal_list_prominent_all, by = 'journal')

journal_list_random_all <- journal_list_random_all %>%
  select(journal = Journal, WOS_first_psych_category)

d_journals_random <- left_join(d_journals_random, journal_list_random_all, by = 'journal')

journal_list_prominent_all <- journal_list_prominent_all %>%
  select(-WOS_first_psych_category)
  
d_journals_random <- left_join(d_journals_random, journal_list_prominent_all, by = 'journal')

tmp <- d_journals_random %>% filter(is.na(`2021 JIF`)) %>% distinct(journal, .keep_all = T)
write_csv(tmp,here('data', 'prepareSample', 'journals', '02 - modified', 'we_need_jifs.csv'))
```

# Resolve coding disagreements in articles data

Find cases where primary and secondary coder disagreed on whether to exclude.

```{r}
d_articles %>%
  filter(exclusion_primary != exclusion_secondary)
```

Following protocol, coding discrepancies are resolved by TEH. We now create an `exclusion_final` column which represents the resolved coding. TEH decides to either go with the primary or secondary coder's verdict. For other articles, we use the primary coder's verdict (which is the same as the secondary coder).

```{r}
# create exclusion_final column
d_articles <- d_articles %>%
  mutate(exclusion_final = case_when(
    sampleID == 'random' & article_id == '37' ~ exclusion_primary,
    sampleID == 'random' & article_id == '41' ~ exclusion_primary,
    sampleID == 'random' & article_id == '68' ~ exclusion_secondary,
    sampleID == 'random' & article_id == '95' ~ exclusion_secondary,
    sampleID == 'random' & article_id == '103' ~ exclusion_primary,
    sampleID == 'random' & article_id == '120' ~ exclusion_primary,
    sampleID == 'prominent' & article_id == '30' ~ exclusion_secondary,
    sampleID == 'prominent' & article_id == '49' ~ exclusion_primary,
    sampleID == 'prominent' & article_id == '66' ~ exclusion_primary,
    sampleID == 'prominent' & article_id == '98' ~ exclusion_primary,
    TRUE ~ exclusion_primary
  ))

# create exclusion_reason_final column
d_articles <- d_articles %>%
  mutate(exclusion_reason_final = case_when(
    sampleID == 'random' & article_id == '37' ~ exclusion_reason_primary,
    sampleID == 'random' & article_id == '41' ~ exclusion_reason_primary,
    sampleID == 'random' & article_id == '68' ~ exclusion_reason_secondary,
    sampleID == 'random' & article_id == '95' ~ exclusion_reason_secondary,
    sampleID == 'random' & article_id == '103' ~ exclusion_reason_primary,
    sampleID == 'random' & article_id == '120' ~ exclusion_reason_primary,
    sampleID == 'prominent' & article_id == '30' ~ exclusion_reason_secondary,
    sampleID == 'prominent' & article_id == '49' ~ exclusion_reason_primary,
    sampleID == 'prominent' & article_id == '66' ~ exclusion_reason_primary,
    sampleID == 'prominent' & article_id == '98' ~ exclusion_reason_primary,
    TRUE ~ exclusion_reason_primary
  ))
```

Find cases where primary and secondary coder disagreed on why to exclude.

```{r}
# we've already dealt with cases where the decision to exclude differs, so we're not looking only at cases where the decision to exclude matches, but the reason for exclusion differs
d_articles %>%
  filter(exclusion_primary == exclusion_secondary, 
         exclusion_reason_primary != exclusion_reason_secondary) %>%
  select(article_id, sampleID, exclusion_reason_primary, exclusion_reason_secondary)
```
We will resolve these by applying the exclusion criteria hierarchically. In other words, we use the highest level of exclusion criteria assigned by one of the two coders.
1. Access
2. English
3. Retracted 
4. Non-empirical

```{r}
# update exclusion_reason_final column when primary and secondary coder disagree on reason to exclude.
d_articles <- d_articles %>%
  mutate(exclusion_reason_final = case_when(
    sampleID == 'random' & article_id == '14' ~ exclusion_reason_primary,
    sampleID == 'random' & article_id == '35' ~ exclusion_reason_primary,
    sampleID == 'random' & article_id == '54' ~ exclusion_reason_secondary,
    sampleID == 'random' & article_id == '73' ~ exclusion_reason_primary,
    sampleID == 'random' & article_id == '78' ~ exclusion_reason_primary,
    sampleID == 'prominent' & article_id == '29' ~ "RETRACTED", # the article was withdrawn, retracted seems like the closest fit among out labels
    sampleID == 'prominent' & article_id == '37' ~ exclusion_reason_primary,
    sampleID == 'prominent' & article_id == '39' ~ exclusion_reason_primary,
    sampleID == 'prominent' & article_id == '46' ~ exclusion_reason_primary,
    sampleID == 'prominent' & article_id == '54' ~ exclusion_reason_secondary,
    TRUE ~ exclusion_reason_final # if none of the above, retain whatever is in this column already
  ))
```
Finally, let's check anything that was excluded with the reason "OTHER". 

```{r}
d_articles %>% filter(exclusion_reason_final == "OTHER") %>% select(article_id, sampleID)
```
Article ID 68 can reclassifed as "NO ACCESS" and for the other three articles we can create a new post-hoc exclusion category "CONFERENCE ABSTRACT".

```{r}
d_articles <- d_articles %>%
  mutate(exclusion_reason_final = case_when(
    sampleID == 'random' & article_id == '68' ~ "NO ACCESS",
    sampleID == 'prominent' & article_id == '2' ~ "CONFERENCE ABSTRACT",
    sampleID == 'prominent' & article_id == '56' ~ "CONFERENCE ABSTRACT",
    sampleID == 'prominent' & article_id == '85' ~ "CONFERENCE ABSTRACT",
    TRUE ~ exclusion_reason_final # if none of the above, retain whatever is in this column already
  ))
```
We should now have resolved coding for all exclusion decisions and exclusion reasons in d_articles

```{r}
d_articles %>%
  count(exclusion_final, exclusion_reason_final)
```

Now for articles that are retained, we need to check if they have the same classification in `ppc_linked`.

```{r}
d_articles %>%
  filter(exclusion_final == "RETAIN",
         ppc_linked_primary != ppc_linked_secondary)
```

There appears to be one case where the primary coder did not identify any PPC links, but the secondary coder did. After review, TEH determines that there is a linked PPC for this article. Thus for this article, the final coding is the same as the secondary coder's classification, and for all other articles we use the primary coder's classification (which is the same as the secondary coders in those cases).

```{r}
d_articles <- d_articles %>%
  mutate(ppc_linked_final = case_when(
    exclusion_final == "EXCLUDE" ~ NA_character_, # if article is excluded, use NA
    sampleID == 'prominent' & article_id == '38' ~ ppc_linked_secondary,
    exclusion_final == "RETAIN" & exclusion_primary == "RETAIN" ~ ppc_linked_primary,
    exclusion_final == "RETAIN" & exclusion_secondary == "RETAIN" ~ ppc_linked_secondary,
    TRUE ~ "ERROR" # if none of the above, retain whatever is in this column already
  ))
```
# Resolve coding disagreements in journals data

Note â€” its easier to do this in the original spreadsheet â€” for each journal I've added a new row with coder initials "FINAL (TEH)". If primary and secondary coding are aligned I just copied their coding into this row. If there were differences, I resolved them and entered the final decision into the new row.

Make a tibble containing only the final coding for journals.\

```{r}
d_journals_final <- d_journals %>%
  filter(coder_id == "FINAL (TEH)") %>% # select only the final coding
  select(-coder_id, -timestamps) # drop the coder_id and timestamps columns
```
# Journals data - exclusions


```{r}
d_journals_final_eligible <- d_journals_final %>%
  filter(journal_empirical == "Yes") %>%
  select(-journal_empirical)
```


# Journals data â€” reorganise

Currently we have one row per journal, and sometimes more than one PPC per journal. To make analysis easier, let's switch the data frame from wide to long format (i.e., switch to one row per PPC instead of one row per journal).

```{r}
d_journals_final_eligible <- d_journals_final_eligible %>%
  pivot_longer( # pivot to long format
    cols = c(-journal,-sampleID, -anyPPC,-general_note),
    names_to = c("PPC_type", ".value"), 
    names_sep = "_ppc_"
  )
```

# Journals data â€” Harmonization 

## Harmonize length limits

Journals used different units to report length limits (e.g., pages, lines, characters, words). We will convert these various units to words using the following approximations.

```{r}
pageToWord <- 500 # using our own recent papers as a guide, we estimate one page to be approximately 500 words. Thus, any limits stated with page units need to be multiplied by 500 to convert to words
charToWord <- 6 # using our own recent papers as a guide, we estimate an average of 6 characters per word. Thus, any limits stated with character units need to be divided by 6 to convert to words
linesToWord <- 10 # after inspecting articles published by journals that use line units, we estimate an average of 10 words per line. Thus any limits stated with line units need to be multiplied by ten to convert to words
```

We will also harmonize differences in data entry formatting, e.g., some coders used quotation marks, commas etc. Any qualitative limits will be designated as such.

```{r}
d_journals_final_eligible <- d_journals_final_eligible %>% 
  mutate(length_harmonized = str_remove_all(length, pattern = '"'), #  remove any quotation marks
         length_harmonized = str_remove(length_harmonized, pattern = fixed("YES (copy and paste the limits in the 'other' section below), ")),# remove data entry question text
         length_harmonized = case_when(
           length_harmonized == "1,000 words" ~ "1000",
           length_harmonized == "1,500 words (one figure and/or one table allowed within word count)" ~ "1500",
           length_harmonized == "1000 words" ~ "1000",
           length_harmonized == "16 pages" ~ as.character(16*pageToWord),
           length_harmonized == "2000 words" ~ "2000",
           length_harmonized == "265 lines of text including references" ~ as.character(265*linesToWord),
           length_harmonized == "3500 words (title page and references included)" ~ "3500",
           length_harmonized == "400 words" ~ "400",
           length_harmonized == "5 pages, including abstract, references, tables, and figures." ~ as.character(5*pageToWord),
           length_harmonized == "500 words" ~ "500",
           length_harmonized == "600-800 words" ~ "800",
           length_harmonized == "750 words" ~ "750",
           length_harmonized == "Approx. 1,000 words" ~ "1000",
           length_harmonized == "approximately 1,000 words" ~ "1000",
           length_harmonized == "as concise as possible, and ideally not exceed 1,200 words" ~ "1200",
           length_harmonized == "at maximum half the length of the target article." ~ "Qualitative",
           length_harmonized == "Maximum length: 1100 words." ~ "1100",
           length_harmonized == "short" ~ "Qualitative",
           length_harmonized == "up to 2,000 words counting 500 words per table and figure" ~ "2000",
           TRUE ~ length_harmonized
         )) 
```

## Harmonize time-to-submit limits

Journals used different units to report time limits (e.g., weeks, months, years). We will convert these various units to weeks using the following approximations.

```{r}
monthToWeek <- 4.35 # number to multiply months by to get weeks
yearToWeek <- 52 # number to multiply years by to get weeks
```

We will also harmonize differences in data entry formatting, e.g., some coders used quotation marks, commas etc. Any qualitative limits will be designated as such.

```{r}
d_journals_final_eligible <- d_journals_final_eligible %>% 
  mutate(time_harmonized = str_remove_all(time, pattern = '"'), #  remove any quotation marks
         time_harmonized = str_remove(time_harmonized, pattern = fixed("YES (provide detail of time limits below), ")),# remove data entry question text
         time_harmonized = case_when(
           time_harmonized == "3 months" ~ as.character(3*monthToWeek),
           time_harmonized == "6 months" ~ as.character(6*monthToWeek),
           time_harmonized == "9 months" ~ as.character(9*monthToWeek),
           time_harmonized == "Draft proposed comments will be due on a tight time- line (i.e., 2â€“ 4 weeks after solicitation), to be determined by the Editor." ~ "4",
           time_harmonized == "he Commentary mechanism is most effective when used to address a contemporary publication" ~ "Qualitative",
           time_harmonized == "Matters Arising articles are interesting and timely scientific or academic comments" ~ "Qualitative",
           time_harmonized == "recent" ~ "Qualitative",
           time_harmonized == "recently published" ~ "Qualitative",
           time_harmonized == "UNCLEAR (provide detail in the 'other' section below), recently published" ~ "Qualitative",
           time_harmonized == "YES (copy and paste the limits in the 'other' section below), 1-year (except for a test of replication)" ~ as.character(1*yearToWeek),
           TRUE ~ time_harmonized
         )) 
```

## Harmonize reference limits

For reference limits we need to harmonize differences in data entry formatting. Additionally, when references are included in the overall length limit, we will re-code these as "NOT STATED", because no specific reference limit has been stated.

```{r}
d_journals_final_eligible <- d_journals_final_eligible %>% 
  mutate(ref_harmonized = str_remove_all(ref, pattern = '"'), #  remove any quotation marks
         ref_harmonized = str_remove(ref_harmonized, pattern = fixed("YES (provide number of references below), ")),# remove data entry question text
         ref_harmonized = str_remove(ref_harmonized, pattern = fixed("YES (copy and paste the limits in the 'other' section below), ")),# remove data entry question text
         ref_harmonized = case_when(
           ref_harmonized == "20 not hard-and-fast limits" ~ "20",
           ref_harmonized == "265 lines of text including references" ~ "NOT STATED",
           ref_harmonized == "contributions may have up to 15 references" ~ "15",
           ref_harmonized == "Included in 16 page overall limit" ~ "NOT STATED",
           ref_harmonized == "No more than 5 references" ~ "5",
           ref_harmonized == "overall limit is 265 lines of text including references" ~ "NOT STATED",
           TRUE ~ ref_harmonized
         )) 
```

## Harmonize PPC names

Currently the PPC names are copied verbatim from the journal websites but many of them are basically the same name with small grammatical differences (e.g., letters, letter to the editor etc.). For analysis, we need to harmonize these names.

Firstly, we will harmonize names that are grammatically similar. We will then examine conceptual similarity and see if we can summarise the types into a few high level categories. A guiding assumption here is that we can capture most PPC types with three categories (based on personal experience and empirical data, Hardwicke et al. 2022):

* letters to the editor - tend to be shorter articles
* commentaries - tend to be longer articles
* web comments - tend be to be short informal comments, usually appearing below articles on the journal website

If PPCs we have identified clearly do not fit into these categories, we will categorize them as "OTHER". 

Firstly, specify PPC names that we want to convert to different harmonized names.

```{r}
commentaries <- c("Brief comment", "Brief Comment", "commentaries", "Commentaries", "Commentary", "Comments", "Matters Arising", "Observations & Commentaries", "Open peer commentaries", "Short Communications and Commentaries", "Short Research Notes", "Text review")
letters <- c("Letter", "Letters", "Letter to the editor", "Letters to the editor", "letters to the editor", "Letters to the Editor.", "letters to the editors", "Letters to the Editors")
# web_comments <- c()
other <- c("Verification reports")
```

```{r}
d_journals_final_eligible <- d_journals_final_eligible %>%
  mutate(name_harmonized = case_when(
    name %in% commentaries ~ "Commentary",
    name %in% letters ~ "Letters",
    name %in% other ~ "Other"
  ))
```

# Final tests

Now check that `journal_empirical` contains only 'Yes' or 'No'. When we first run the test we get unexpected values.

and convert these to `TRUE` and `FALSE` respectively.

```{r}
assert_that(
  all(d_journals$journal_empirical %in% c("Yes", "No")),
  msg = "Found unexpected values in journal_empirical column"
)
```


